{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "     NO   KODE                           NAMA BAHAN       SUMBER   AIR ENERGI  \\\n",
      "0  NaN    NaN                                  NaN          NaN   (g)  (Kal)   \n",
      "1    1  AR001                 Beras giling, mentah   KZGMI-2001    12    357   \n",
      "2    2  AR002      Beras giling var pelita, mentah  KZGPI- 1990  11.4    369   \n",
      "3    3  AR003    Beras giling var rojolele, mentah  KZGPI- 1990    12    357   \n",
      "4    5  AR004  Beras jagung kuning, kering, mentah   KZGMI-2001  10.8    358   \n",
      "\n",
      "  PROTEIN LEMAK    KH SERAT  ... TEMBAGA  SENG RETINOL  B-KAR KAR-TOTAL  \\\n",
      "0     (g)   (g)   (g)   (g)  ...    (mg)  (mg)   (mcg)  (mcg)     (mcg)   \n",
      "1     8.4   1.7  77.1   0.2  ...     0.1   0.5       0      0         0   \n",
      "2     9.5   1.4  77.1   0.4  ...       0     0       0      0         0   \n",
      "3     8.4   1.7  77.1   0.2  ...    0.14   0.1     NaN      0        80   \n",
      "4     5.5   0.1  82.7    10  ...     0.1   4.1     NaN    641       NaN   \n",
      "\n",
      "  THIAMIN RIBOFLAVIN NIASIN VIT_C Unnamed: 25  \n",
      "0    (mg)       (mg)   (mg)  (mg)         NaN  \n",
      "1     0.2       0.08    2.6     0       100.0  \n",
      "2    0.26          0      0     0       100.0  \n",
      "3     0.2       0.02    1.5     0       100.0  \n",
      "4    0.12       0.08      1     3       100.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "Filtered Dataset:\n",
      "     KODE                           NAMA BAHAN       SUMBER  ENERGI PROTEIN  \\\n",
      "0  AR001                 Beras giling, mentah   KZGMI-2001   357.0     8.4   \n",
      "1  AR002      Beras giling var pelita, mentah  KZGPI- 1990   369.0     9.5   \n",
      "2  AR003    Beras giling var rojolele, mentah  KZGPI- 1990   357.0     8.4   \n",
      "3  AR004  Beras jagung kuning, kering, mentah   KZGMI-2001   358.0     5.5   \n",
      "4  AR005   Beras jagung putih, kering, mentah   KZGMI-2001   307.0     4.8   \n",
      "\n",
      "  LEMAK    KH SERAT  \n",
      "0   1.7  77.1   0.2  \n",
      "1   1.4  77.1   0.4  \n",
      "2   1.7  77.1   0.2  \n",
      "3   0.1  82.7    10  \n",
      "4   0.1  71.8    10  \n",
      "Clustered data saved to 'tkpi_filtered_clustered.csv'\n",
      "Clustered Dataset:\n",
      "     KODE                           NAMA BAHAN       SUMBER  ENERGI PROTEIN  \\\n",
      "0  AR001                 Beras giling, mentah   KZGMI-2001   357.0     8.4   \n",
      "1  AR002      Beras giling var pelita, mentah  KZGPI- 1990   369.0     9.5   \n",
      "2  AR003    Beras giling var rojolele, mentah  KZGPI- 1990   357.0     8.4   \n",
      "3  AR004  Beras jagung kuning, kering, mentah   KZGMI-2001   358.0     5.5   \n",
      "4  AR005   Beras jagung putih, kering, mentah   KZGMI-2001   307.0     4.8   \n",
      "\n",
      "  LEMAK    KH SERAT  Cluster  \n",
      "0   1.7  77.1   0.2        0  \n",
      "1   1.4  77.1   0.4        0  \n",
      "2   1.7  77.1   0.2        0  \n",
      "3   0.1  82.7    10        0  \n",
      "4   0.1  71.8    10        0  \n",
      "New Cluster Centroids:\n",
      " [[-0.33411351 -0.27353929 -0.39132534 -0.07401933 -0.06071779]\n",
      " [-1.15795546 -0.51940605 -0.44237553  7.00363888  9.13052046]\n",
      " [ 1.38343368  1.11602798  1.58495025  0.02544628 -0.11017662]]\n",
      "Number of rows in the original dataset (tkpi.csv): 886\n",
      "Number of rows in the filtered dataset (tkpi_filtered.csv): 782\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('tkpi.csv')\n",
    "\n",
    "# Display the first few rows of the original dataset\n",
    "print(\"Original Dataset:\\n\", data.head())\n",
    "\n",
    "# Step 2: Clean the dataset by removing the first row and non-numeric columns\n",
    "df_cleaned = data.drop([0])  # Drop the header-like row\n",
    "\n",
    "# Step 3: Remove rows where 'KODE' is NaN (to avoid errors during filtering)\n",
    "df_cleaned = df_cleaned.dropna(subset=['KODE'])\n",
    "\n",
    "# Step 4: Filter data where 'KODE' starts with letters A-H using regex\n",
    "df_cleaned = df_cleaned[df_cleaned['KODE'].str.match(r'^[A-Ha-h]')]\n",
    "df_cleaned = df_cleaned[~df_cleaned['NAMA BAHAN'].str.contains(r'anak|babi|darah', case=False, na=False)]\n",
    "\n",
    "# Step 5: Select only the desired columns: 'KODE', 'NAMA BAHAN', 'SUMBER', and numeric columns\n",
    "desired_columns = ['KODE', 'NAMA BAHAN', 'SUMBER', 'ENERGI', 'PROTEIN', 'LEMAK', 'KH', 'SERAT']\n",
    "df_final = df_cleaned[desired_columns]\n",
    "\n",
    "# Step 6: Save the filtered data to a new CSV file\n",
    "df_final.to_csv('tkpi_filtered.csv', index=False)\n",
    "\n",
    "# Step 7: Load the newly saved CSV file (filtered dataset)\n",
    "filtered_data = pd.read_csv('tkpi_filtered.csv')\n",
    "\n",
    "# Display the first few rows of the filtered data\n",
    "print(\"Filtered Dataset:\\n\", filtered_data.head())\n",
    "\n",
    "# Step 8: Select relevant numeric columns for clustering\n",
    "numeric_columns = ['ENERGI', 'PROTEIN', 'LEMAK', 'KH', 'SERAT']\n",
    "\n",
    "# Step 9: Convert the selected columns to numeric, forcing errors='coerce' to handle non-numeric values properly\n",
    "df_numeric = filtered_data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Step 10: Handle missing values by filling them with the mean of the column\n",
    "df_numeric = df_numeric.fillna(df_numeric.mean())\n",
    "\n",
    "# Step 11: Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# Step 12: Apply K-Means clustering with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "filtered_data['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Step 13: Save the clustered data to a new CSV file\n",
    "filtered_data.to_csv('tkpi_filtered.csv', index=False)\n",
    "print(\"Clustered data saved to 'tkpi_filtered_clustered.csv'\")\n",
    "\n",
    "# Step 14: Print the first few rows of the clustered data\n",
    "print(\"Clustered Dataset:\\n\", filtered_data.head())\n",
    "\n",
    "# Step 15: Show new cluster centroids\n",
    "print(\"New Cluster Centroids:\\n\", kmeans.cluster_centers_)\n",
    "\n",
    "print(f\"Number of rows in the original dataset (tkpi.csv): {len(data)}\")\n",
    "print(f\"Number of rows in the filtered dataset (tkpi_filtered.csv): {len(df_final)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.049796873329014335\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean Squared Error (MSE): 0.049796873329014335\n",
      "Total Calories from Meals: 1279.00 vs Adjusted BMR: 1453.85\n",
      "=== Informasi Pengguna ===\n",
      "BMR (sebelum penyesuaian): 1817.32 kalori\n",
      "Tujuan: Lose berat badan\n",
      "BMR yang disesuaikan (kebutuhan kalori per hari): 1453.85 kalori\n",
      "\n",
      "Rekomendasi Makanan\n",
      "\n",
      "Breakfast:\n",
      "                     NAMA BAHAN  ENERGI  PROTEIN  LEMAK    KH\n",
      "905                Udang, segar    91.0     21.0    0.2   0.1\n",
      "782  Ayam goreng kentucky, dada   298.0     34.2   16.8   0.1\n",
      "300       Kacang kedelai, rebus   189.0     20.2    8.2  12.7\n",
      "580            Kaparende, sayur    38.0      2.4    2.0   2.6\n",
      "410       Daun kacang ma, segar    36.0      2.9    0.6   6.8\n",
      "153            Sagu aren, segar   231.0      0.6    0.2  56.6\n",
      "\n",
      "Lunch:\n",
      "                 NAMA BAHAN  ENERGI  PROTEIN  LEMAK    KH\n",
      "868      Ikan mayong, segar    97.0     17.9    2.0   0.4\n",
      "952   Rebon, kering, mentah   299.0     59.4    3.6   3.2\n",
      "366  Tempe kacang belimbing   212.0     17.5   10.0  12.9\n",
      "600             Shabu-shabu    88.0      3.2    8.0   0.8\n",
      "568             Ares, sayur   113.0      0.9    7.2  11.2\n",
      "143          Ganyong, segar    77.0      0.6    0.2  18.4\n",
      "155            Sagu lempeng   347.0      0.9    0.3  85.2\n",
      "\n",
      "Dinner:\n",
      "                   NAMA BAHAN  ENERGI  PROTEIN  LEMAK    KH\n",
      "809      Lawar penyu, masakan   141.0     23.0    1.5   7.6\n",
      "300     Kacang kedelai, rebus   189.0     20.2    8.2  12.7\n",
      "586                 Olah-olah     9.0      2.1    6.0   7.1\n",
      "571             Botok lamtoro   186.0     11.7    9.7  13.0\n",
      "165  Ubi jalar tinta/kemayung   108.0      0.5    0.4  25.6\n",
      "\n",
      "Snacks (Buah-buahan):\n",
      "               NAMA BAHAN  ENERGI  PROTEIN  LEMAK    KH\n",
      "683  Pisang goroho, segar   119.0      1.5    0.2  27.9\n",
      "611      Belimbing, segar    36.0      0.4    0.4   8.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# calculate bmr\n",
    "def calculate_bmr(sex, age, weight, height, activity_level):\n",
    "    if sex == 'male':\n",
    "        bmr = 88.362 + (13.397 * weight) + (4.799 * height) - (5.677 * age)\n",
    "    else:\n",
    "        bmr = 447.593 + (9.247 * weight) + (3.098 * height) - (4.330 * age)\n",
    "    \n",
    "    # penyesuaian bmr berdasar level aktivitas\n",
    "    activity_multiplier = {\n",
    "        'sedentary': 1.3,\n",
    "                'lowactive': 1.5,\n",
    "                'active': 1.7,\n",
    "                'veryactive': 2\n",
    "    }\n",
    "    bmr *= activity_multiplier.get(activity_level, 1.2)\n",
    "    \n",
    "    return bmr\n",
    "\n",
    "# bmr berdasar tujuan diet\n",
    "def adjust_bmr_for_goal(bmr, goal):\n",
    "    if goal == 'lose':\n",
    "        return bmr * 0.8  # dikurangi 20%\n",
    "    elif goal == 'gain':\n",
    "        return bmr * 1.2  # ditambah 20% \n",
    "    else:\n",
    "        return bmr  # Maintain weight\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv('tkpi_filtered_clustered.csv')  \n",
    "\n",
    "# Data Preprocessing \n",
    "def preprocess_data_with_kmeans(data):\n",
    "    # Check if the columns are strings and replace commas if needed\n",
    "    for column in ['ENERGI', 'PROTEIN', 'LEMAK', 'KH', 'SERAT']:\n",
    "        if data[column].dtype == 'object':  # Only apply .str.replace if column is an object (string)\n",
    "            data[column] = data[column].str.replace(',', '.').astype(float)\n",
    "        else:\n",
    "            data[column] = data[column].astype(float)  # Ensure numeric columns are float\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Add the 'Cluster' feature generated by K-Means clustering\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[['ENERGI', 'PROTEIN', 'LEMAK', 'KH', 'SERAT', 'Cluster']])\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=['ENERGI', 'PROTEIN', 'LEMAK', 'KH', 'SERAT', 'Cluster'])\n",
    "    \n",
    "    return scaled_df, scaler\n",
    "\n",
    "# Preprocess the dataset with cluster feature\n",
    "processed_data, scaler = preprocess_data_with_kmeans(data)\n",
    "\n",
    "# split fitur (X) and target (y)\n",
    "X = processed_data[['PROTEIN', 'LEMAK', 'KH', 'SERAT','Cluster']] \n",
    "y = processed_data['ENERGI']  \n",
    "\n",
    "# training dan testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training (Random Forest Regressor)\n",
    "def train_random_forest(X_train, y_train):\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    return rf_model\n",
    "\n",
    "rf_model = train_random_forest(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    return mse\n",
    "\n",
    "evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "# Model Optimization using GridSearchCV\n",
    "def optimize_model(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "optimized_rf_model = optimize_model(X_train, y_train)\n",
    "\n",
    "# Final evaluation with optimized model\n",
    "evaluate_model(optimized_rf_model, X_test, y_test)\n",
    "\n",
    "# mencari makanan berdasar kalori dari kategori tertentu\n",
    "def find_foods_by_category(target_calories, data, category_prefix, max_items=5):\n",
    "    total_calories = 0\n",
    "    selected_foods = pd.DataFrame()\n",
    "\n",
    "    # Filter data berdasar kategori\n",
    "    category_data = data[data['KODE'].str.startswith(tuple(category_prefix))]\n",
    "\n",
    "    if category_data.empty:\n",
    "        print(f\"No data available for categories {category_prefix}\")\n",
    "        return selected_foods  # Return an empty DataFrame if no data is available\n",
    "\n",
    "    # looping untuk mencari kombinasi makanan agar mencapai terget kalori\n",
    "    while total_calories < target_calories and len(selected_foods) < max_items:\n",
    "        # Randomly sample foods from the dataset in the specific category\n",
    "        possible_food = category_data.sample(n=1, replace=False)\n",
    "        selected_foods = pd.concat([selected_foods, possible_food])\n",
    "        total_calories = selected_foods['ENERGI'].sum()\n",
    "\n",
    "        # Stop when we exceed the target calories\n",
    "        if total_calories >= target_calories:\n",
    "            break\n",
    "\n",
    "    return selected_foods\n",
    "\n",
    "# rekomendasi makanan dengan porsi seimbang \n",
    "def recommend_balanced_meals(bmr, data, protein_threshold=15, carb_threshold=20, fat_threshold=20, fiber_threshold=20):\n",
    "    breakfast_calories = bmr * 0.25\n",
    "    lunch_calories = bmr * 0.35\n",
    "    dinner_calories = bmr * 0.3\n",
    "    snack_calories = bmr * 0.1  \n",
    "\n",
    "    \n",
    "    high_protein_low_carb = data[\n",
    "        (data['PROTEIN'] >= protein_threshold) & \n",
    "        (data['KH'] <= carb_threshold) & \n",
    "        (data['LEMAK'] <= fat_threshold) & \n",
    "        (data['SERAT'] <= fiber_threshold)\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Karbohidrat should not be filtered by the same conditions, so no need for high protein, low carb filter for 'A', 'B'\n",
    "    karbo_data = data[data['KODE'].str.startswith(('A', 'B'))]\n",
    "\n",
    "    # pembagian alokasi porsi per kategori dalam sekali makan\n",
    "    def allocate_category_calories(total_calories):\n",
    "        protein_calories = total_calories * 0.3\n",
    "        nabati_calories = total_calories * 0.2\n",
    "        sayur_calories = total_calories * 0.3\n",
    "        karbo_calories = total_calories * 0.2\n",
    "        return protein_calories, nabati_calories, sayur_calories, karbo_calories, \n",
    "\n",
    "    # Breakfast\n",
    "    breakfast_protein_cal, breakfast_nabati_cal, breakfast_sayur_cal, breakfast_karbo_cal = allocate_category_calories(breakfast_calories)\n",
    "    breakfast_protein = find_foods_by_category(breakfast_protein_cal, high_protein_low_carb, category_prefix=['F', 'G', 'H'])\n",
    "    breakfast_nabati = find_foods_by_category(breakfast_nabati_cal, high_protein_low_carb, category_prefix=['C'])\n",
    "    breakfast_sayur = find_foods_by_category(breakfast_sayur_cal, data, category_prefix=['D'], max_items=2)\n",
    "    breakfast_karbo = find_foods_by_category(breakfast_karbo_cal, karbo_data, category_prefix=['AR', 'BR'])  \n",
    "    breakfast_foods = pd.concat([breakfast_protein, breakfast_nabati, breakfast_sayur, breakfast_karbo])\n",
    "\n",
    "    # Lunch\n",
    "    lunch_protein_cal, lunch_nabati_cal, lunch_sayur_cal, lunch_karbo_cal = allocate_category_calories(lunch_calories)\n",
    "    lunch_protein = find_foods_by_category(lunch_protein_cal, high_protein_low_carb, category_prefix=['F', 'G', 'H'])\n",
    "    lunch_nabati = find_foods_by_category(lunch_nabati_cal, high_protein_low_carb, category_prefix=['C'])\n",
    "    lunch_sayur = find_foods_by_category(lunch_sayur_cal, data, category_prefix=['D'], max_items=2)\n",
    "    lunch_karbo = find_foods_by_category(lunch_karbo_cal, karbo_data, category_prefix=['AR', 'BR'])  \n",
    "    lunch_foods = pd.concat([lunch_protein, lunch_nabati, lunch_sayur, lunch_karbo])\n",
    "\n",
    "    # Dinner\n",
    "    dinner_protein_cal,dinner_nabati_cal, dinner_sayur_cal, dinner_karbo_cal = allocate_category_calories(dinner_calories)\n",
    "    dinner_protein = find_foods_by_category(dinner_protein_cal, high_protein_low_carb, category_prefix=['F', 'G', 'H'])\n",
    "    dinner_nabati = find_foods_by_category(dinner_nabati_cal, high_protein_low_carb, category_prefix=['C'])\n",
    "    dinner_sayur = find_foods_by_category(dinner_sayur_cal, data, category_prefix=['D'], max_items=2)\n",
    "    dinner_carbo = find_foods_by_category(dinner_karbo_cal, karbo_data, category_prefix=['AR', 'BR']) \n",
    "    dinner_foods = pd.concat([dinner_protein, dinner_nabati, dinner_sayur, dinner_carbo])\n",
    "\n",
    "    # Snacks\n",
    "    fruit_snacks = find_foods_by_category(snack_calories, data, category_prefix=['ER'], max_items=3)\n",
    "\n",
    "    # menghitung total kalori\n",
    "    total_calories = (breakfast_foods['ENERGI'].sum() +\n",
    "                      lunch_foods['ENERGI'].sum() +\n",
    "                      dinner_foods['ENERGI'].sum() +\n",
    "                      fruit_snacks['ENERGI'].sum())\n",
    "\n",
    "    # memastikan total kalori mendekati bmr yang dibutuhkan\n",
    "    if total_calories > bmr:\n",
    "        excess_calories = total_calories - bmr\n",
    "        # Adjust meals down if exceeded\n",
    "        all_foods = pd.concat([breakfast_foods, lunch_foods, dinner_foods, fruit_snacks])\n",
    "        all_foods = all_foods[all_foods['ENERGI'].cumsum() <= bmr]\n",
    "        total_calories = all_foods['ENERGI'].sum()\n",
    "\n",
    "    print(f\"Total Calories from Meals: {total_calories:.2f} vs Adjusted BMR: {bmr:.2f}\")\n",
    "    \n",
    "    return breakfast_foods, lunch_foods, dinner_foods, fruit_snacks\n",
    "\n",
    "# user input\n",
    "user_input = {\n",
    "    'sex': 'female',\n",
    "    'age': 24,\n",
    "    'weight': 72,  # in kg\n",
    "    'height': 163,  # in cm\n",
    "    'activity_level': 'light',  # activity level (sedentary, light, moderate, active, very active)\n",
    "    'goal': 'lose'  # can be 'lose', 'gain', or 'maintain'\n",
    "}\n",
    "\n",
    "# hitung bmr\n",
    "bmr = calculate_bmr(user_input['sex'], user_input['age'], user_input['weight'], user_input['height'], user_input['activity_level'])\n",
    "\n",
    "# penyesuaian bmr\n",
    "bmr_adjusted = adjust_bmr_for_goal(bmr, user_input['goal'])\n",
    "\n",
    "# rekomendasi diet\n",
    "breakfast, lunch, dinner, snacks = recommend_balanced_meals(bmr_adjusted, data)\n",
    "\n",
    "# Print\n",
    "print(\"=== Informasi Pengguna ===\")\n",
    "print(f\"BMR (sebelum penyesuaian): {bmr:.2f} kalori\")\n",
    "print(f\"Tujuan: {user_input['goal'].capitalize()} berat badan\")\n",
    "print(f\"BMR yang disesuaikan (kebutuhan kalori per hari): {bmr_adjusted:.2f} kalori\")\n",
    "print(\"\\nRekomendasi Makanan\")\n",
    "print(\"\\nBreakfast:\")\n",
    "print(breakfast[['NAMA BAHAN','ENERGI', 'PROTEIN', 'LEMAK', 'KH']])\n",
    "print(\"\\nLunch:\")\n",
    "print(lunch[['NAMA BAHAN','ENERGI', 'PROTEIN', 'LEMAK', 'KH']])\n",
    "print(\"\\nDinner:\")\n",
    "print(dinner[['NAMA BAHAN','ENERGI', 'PROTEIN', 'LEMAK', 'KH']])\n",
    "print(\"\\nSnacks (Buah-buahan):\")\n",
    "print(snacks[['NAMA BAHAN','ENERGI', 'PROTEIN', 'LEMAK', 'KH']])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
